data:
  sequence_iterator:
    classname: ConnorGemma2TokenSequenceLoader
    kwargs:
      sequence_length: 256
  activations_harvester:
    llms:
      - name: google/gemma-2-2b
      - name: google/gemma-2-2b-it
    layer_indices_to_harvest: [13]
    harvesting_batch_size: 512
  activations_shuffle_buffer_size: 8_192
crosscoder:
  hidden_dim: 6144
train:
  batch_size: 32
  optimizer:
    initial_learning_rate: 5e-5
    last_pct_of_steps: 0.2
  lambda_s_max: 5
  lambda_s_n_steps: 1000
  num_steps: 10_000
  save_every_n_steps: 1000
  log_every_n_steps: 20
experiment_name: l1_crosscoder_gemma_2_2b_layer_13
wandb: true
